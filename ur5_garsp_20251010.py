import time
import os
import datetime
import cv2
import numpy as np
import math
import configparser
from ultralytics import YOLO
from ur5_robot import UR_Robot
from real.realsenseD415 import Camera


class YOLORobotPoseCalculator:
    def __init__(self, cam2end_path, camera_params_path, yolo_model_path, robot, camera):
        # è®¾å¤‡å¯¹è±¡
        self.robot = robot
        self.camera = camera  # Realsenseæ·±åº¦ç›¸æœºå¯¹è±¡

        # 1. åŠ è½½å‚æ•°
        self.cam2end = self.load_cam2end(cam2end_path)
        self.end2cam = self.calculate_transform_inverse(self.cam2end)
        self.camera_matrix, self.dist_coeffs = self.load_camera_params(camera_params_path)

        # 2. åŠ è½½YOLOæ¨¡å‹
        self.yolo_model = YOLO(yolo_model_path)

        # 3. ç›®æ ‡é…ç½®
        self.target_class_id = 1  # ç›®æ ‡ç±»åˆ«ID
        self.conf_threshold = 0.3
        self.iou_threshold = 0.3

        # ç±»åˆ«æ£€æµ‹æ ‡è®°
        self.found_target = False
        self.last_robot_pose = None  # å­˜å‚¨æœ€æ–°çš„è§£ç®—ç»“æœ
        self.last_center_depth = None  # æ–°å¢ï¼šå­˜å‚¨æœ€æ–°ä¸­å¿ƒç‚¹æ·±åº¦å€¼ï¼ˆç±³ï¼‰

        # ä¸­å¿ƒç‚¹ç»˜åˆ¶å‚æ•°
        self.center_outer_radius = 10
        self.center_inner_radius = 3
        self.center_outer_color = (0, 0, 0)
        self.center_inner_color = (0, 255, 255)
        self.center_outer_thickness = 2
        self.center_inner_thickness = -1

        # moveLè¿åŠ¨å‚æ•°
        self.moveL_speed = 0.1  # çº¿æ€§è¿åŠ¨é€Ÿåº¦(m/s)
        self.moveL_acc = 0.1  # çº¿æ€§è¿åŠ¨åŠ é€Ÿåº¦(m/sÂ²)
        self.moveL_offset = [-0.05, -0.5, 0.61, 0.034, -3.108, 0.630]  # ç›®æ ‡ä½å§¿åç§»é‡

        # å®‰å…¨èŒƒå›´é…ç½®
        self.SAFE_POSITION_RANGE = {
            "X": [-0.8, 0.2],
            "Y": [-0.6, 0.6],
            "Z": [0.05, 0.8]
        }
        self.SAFE_ORIENTATION_RANGE = {
            "Roll": [-math.pi, math.pi],
            "Pitch": [-math.pi / 2, math.pi / 2],
            "Yaw": [-math.pi, math.pi]
        }

    # ç›¸æœºå‚æ•°åŠ è½½æ–¹æ³•ï¼ˆä¸å˜ï¼‰
    def load_camera_params(self, file_path):
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"ç›¸æœºå‚æ•°æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")

        config = configparser.ConfigParser()
        config.read(file_path)

        # è¯»å–å†…å‚ï¼ˆfx, fyä¸ºç„¦è·ï¼›cx, cyä¸ºä¸»ç‚¹åæ ‡ï¼‰
        fx = float(config.get('camera_parameters', 'fx'))
        fy = float(config.get('camera_parameters', 'fy'))
        cx = float(config.get('camera_parameters', 'cx'))
        cy = float(config.get('camera_parameters', 'cy'))

        camera_matrix = np.array([[fx, 0, cx],
                                  [0, fy, cy],
                                  [0, 0, 1]], dtype=np.float32)

        # è¯»å–ç•¸å˜ç³»æ•°ï¼ˆRealsenseé€šå¸¸å·²åšç•¸å˜æ ¡æ­£ï¼Œæ­¤å¤„ä¿ç•™å…¼å®¹ï¼‰
        k1 = float(config.get('distortion_parameters', 'k1', fallback=0.0))
        k2 = float(config.get('distortion_parameters', 'k2', fallback=0.0))
        p1 = float(config.get('distortion_parameters', 'p1', fallback=0.0))
        p2 = float(config.get('distortion_parameters', 'p2', fallback=0.0))
        k3 = float(config.get('distortion_parameters', 'k3', fallback=0.0))

        dist_coeffs = np.array([[k1, k2, p1, p2, k3]], dtype=np.float32)
        return camera_matrix, dist_coeffs

    # ç›¸æœºåˆ°æœ«ç«¯æ‰§è¡Œå™¨å˜æ¢çŸ©é˜µåŠ è½½æ–¹æ³•ï¼ˆä¸å˜ï¼‰
    def load_cam2end(self, file_path):
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"cam2endæ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")

        cam2end = []
        with open(file_path, 'r') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                row = list(map(float, line.split()))
                if len(row) == 4:
                    row = [x / 1000.0 for x in row]  # æ¯«ç±³â†’ç±³
                    cam2end.append(row)

        if len(cam2end) != 4:
            raise ValueError(f"cam2endçŸ©é˜µéœ€4è¡Œï¼Œå½“å‰{len(cam2end)}è¡Œ")

        return np.array(cam2end, dtype=np.float32)

    # å˜æ¢çŸ©é˜µæ±‚é€†æ–¹æ³•ï¼ˆä¸å˜ï¼‰
    def calculate_transform_inverse(self, transform_mat):
        R = transform_mat[:3, :3]
        t = transform_mat[:3, 3].reshape(3, 1)
        R_inv = R.T
        t_inv = -np.dot(R_inv, t)
        inv_transform = np.eye(4, dtype=np.float32)
        inv_transform[:3, :3] = R_inv
        inv_transform[:3, 3] = t_inv.flatten()
        return inv_transform

    # ç›®æ ‡æ£€æµ‹ï¼ˆåªä¿ç•™ä¸­å¿ƒç‚¹ï¼Œä¸å˜ï¼‰
    def yolo_detect_target(self, color_image):
        display_img = color_image.copy()
        target_center = None  # åªéœ€è¦ç›®æ ‡ä¸­å¿ƒç‚¹ï¼ˆ2Dåƒç´ åæ ‡ï¼‰

        try:
            # YOLOæ£€æµ‹ï¼ˆè¯­ä¹‰åˆ†å‰²æ¨¡å¼ï¼Œç”¨äºå®šä½ç›®æ ‡åŒºåŸŸï¼‰
            results = self.yolo_model(
                color_image,
                conf=self.conf_threshold,
                iou=self.iou_threshold,
                verbose=False,
                imgsz=640
            )
            result = results[0]

            # åˆå§‹åŒ–æ£€æµ‹çŠ¶æ€
            self.found_target = False

            # å¯è§†åŒ–æ£€æµ‹ç»“æœå¹¶æå–ä¸­å¿ƒç‚¹
            if result.masks is not None:
                for mask, cls, conf in zip(result.masks.data, result.boxes.cls, result.boxes.conf):
                    cls_id = int(cls)
                    confidence = float(conf)

                    # åªå¤„ç†ç›®æ ‡ç±»åˆ«
                    if cls_id != self.target_class_id:
                        continue

                    self.found_target = True  # æ ‡è®°ä¸ºæ‰¾åˆ°ç›®æ ‡

                    # ç»˜åˆ¶æ©ç ï¼ˆå¯è§†åŒ–ç›®æ ‡åŒºåŸŸï¼‰
                    mask_np = mask.cpu().numpy().astype(np.uint8) * 255
                    if mask_np.shape != (color_image.shape[0], color_image.shape[1]):
                        mask_np = cv2.resize(mask_np, (color_image.shape[1], color_image.shape[0]))

                    color = (0, 255, 0)  # ç›®æ ‡ç±»åˆ«ç”¨ç»¿è‰²
                    mask_3d = np.stack([mask_np] * 3, axis=-1) / 255.0
                    display_img = cv2.addWeighted(
                        display_img, 1,
                        (mask_3d * color).astype(np.uint8), 0.3, 0
                    )

                    # æ ‡è®°ç±»åˆ«å’Œç½®ä¿¡åº¦
                    x1, y1, x2, y2 = result.boxes.xyxy[0].cpu().numpy()
                    cv2.putText(display_img, f"cls:{cls_id} ({confidence:.2f})",
                                (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX,
                                0.5, color, 2)

                    # æå–ç›®æ ‡ä¸­å¿ƒç‚¹ï¼ˆé‡å¿ƒï¼‰
                    contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    if contours:
                        largest_contour = max(contours, key=cv2.contourArea)
                        cv2.drawContours(display_img, [largest_contour], -1, (255, 0, 0), 2)

                        # è®¡ç®—é‡å¿ƒï¼ˆç›®æ ‡ä¸­å¿ƒç‚¹çš„2Dåƒç´ åæ ‡ï¼‰
                        M = cv2.moments(largest_contour)
                        if M["m00"] != 0:  # é¿å…é™¤ä»¥0
                            cX = int(M["m10"] / M["m00"])
                            cY = int(M["m01"] / M["m00"])
                            target_center = (cX, cY)  # æœ€ç»ˆè·å–çš„2Dä¸­å¿ƒç‚¹

                            # ç»˜åˆ¶ä¸­å¿ƒç‚¹ï¼ˆçªå‡ºæ˜¾ç¤ºï¼‰
                            cv2.circle(display_img, (cX, cY), self.center_outer_radius,
                                       self.center_outer_color, self.center_outer_thickness)
                            cv2.circle(display_img, (cX, cY), self.center_inner_radius,
                                       self.center_inner_color, self.center_inner_thickness)

                            # æ ‡æ³¨ä¸­å¿ƒç‚¹åƒç´ åæ ‡
                            center_text = f"Center: ({cX}, {cY})"
                            cv2.putText(display_img, center_text,
                                        (cX + 15, cY - 15),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

        except Exception as e:
            print(f"æ£€æµ‹å‡ºé”™: {str(e)}")
            return display_img, None  # åªè¿”å›å›¾åƒå’Œä¸­å¿ƒç‚¹ï¼ˆæ— è§’ç‚¹ï¼‰

        return display_img, target_center  # ç§»é™¤è§’ç‚¹è¿”å›ï¼Œåªä¿ç•™ä¸­å¿ƒç‚¹

    # -------------------------- å…³é”®ä¿®æ”¹1ï¼šä¿å­˜æ·±åº¦å€¼åˆ°ç±»å˜é‡ï¼Œç”¨äºåç»­æ˜¾ç¤º --------------------------
    def get_obj2cam_pose(self, target_center_2d, depth_image):
        """
        è¾“å…¥ï¼šç›®æ ‡ä¸­å¿ƒç‚¹2Dåƒç´ åæ ‡ã€æ·±åº¦å›¾
        è¾“å‡ºï¼šç›®æ ‡ä¸­å¿ƒç‚¹åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„3Dåæ ‡ï¼ˆX, Y, Zï¼‰
        æ–°å¢ï¼šå°†æ·±åº¦å€¼ä¿å­˜åˆ°self.last_center_depthï¼Œç”¨äºå®æ—¶æ˜¾ç¤º
        """
        # 1. ç©ºå€¼æ£€æŸ¥
        if target_center_2d is None or depth_image is None:
            print("è­¦å‘Š: ä¸­å¿ƒç‚¹æˆ–æ·±åº¦å›¾ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—ç›¸æœºåæ ‡ç³»åæ ‡")
            self.last_center_depth = None  # æ— æ·±åº¦æ—¶ç½®ç©º
            return None

        cX, cY = target_center_2d  # ä¸­å¿ƒç‚¹2Dåƒç´ åæ ‡ï¼ˆu, vï¼‰
        fx, fy = self.camera_matrix[0, 0], self.camera_matrix[1, 1]  # ç›¸æœºç„¦è·
        cx, cy = self.camera_matrix[0, 2], self.camera_matrix[1, 2]  # ç›¸æœºä¸»ç‚¹åæ ‡

        # 2. è·å–ä¸­å¿ƒç‚¹çš„æ·±åº¦å€¼ï¼ˆRealsenseæ·±åº¦å›¾å•ä½ä¸ºæ¯«ç±³ï¼Œéœ€è½¬æ¢ä¸ºç±³ï¼‰
        depth_roi_size = 5  # æ·±åº¦é‡‡æ ·åŒºåŸŸå¤§å°ï¼ˆå¥‡æ•°ï¼Œé¿å…åç§»ï¼‰
        half_roi = depth_roi_size // 2

        # ç¡®ä¿é‡‡æ ·åŒºåŸŸåœ¨æ·±åº¦å›¾èŒƒå›´å†…
        depth_h, depth_w = depth_image.shape
        start_x = max(0, cX - half_roi)
        end_x = min(depth_w, cX + half_roi + 1)
        start_y = max(0, cY - half_roi)
        end_y = min(depth_h, cY + half_roi + 1)

        # æå–ROIæ·±åº¦åŒºåŸŸå¹¶è¿‡æ»¤æ— æ•ˆå€¼ï¼ˆRealsenseæ— æ•ˆæ·±åº¦ä¸º0ï¼‰
        depth_roi = depth_image[start_y:end_y, start_x:end_x]
        valid_depth = depth_roi[depth_roi > 0]  # è¿‡æ»¤0å€¼ï¼ˆæ— æ•ˆæ·±åº¦ï¼‰

        if len(valid_depth) == 0:
            print(f"è­¦å‘Š: ä¸­å¿ƒç‚¹({cX},{cY})å‘¨å›´æ— æœ‰æ•ˆæ·±åº¦å€¼")
            self.last_center_depth = None  # æ— æœ‰æ•ˆæ·±åº¦æ—¶ç½®ç©º
            return None

        # å–æœ‰æ•ˆæ·±åº¦çš„å¹³å‡å€¼ï¼ˆé™ä½å™ªå£°å½±å“ï¼‰
        avg_depth = np.mean(valid_depth) / 1000.0  # æ¯«ç±³ â†’ ç±³
        self.last_center_depth = round(avg_depth, 4)  # æ–°å¢ï¼šä¿å­˜æ·±åº¦å€¼ï¼ˆä¿ç•™4ä½å°æ•°ï¼‰

        # 3. æ ¸å¿ƒå…¬å¼ï¼šå°†åƒç´ åæ ‡ï¼ˆu, vï¼‰è½¬æ¢ä¸ºç›¸æœºåæ ‡ç³»3Dåæ ‡ï¼ˆX, Y, Zï¼‰
        X_cam = (cX - cx) * avg_depth / fx  # ç›¸æœºåæ ‡ç³»Xè½´ï¼ˆå³ä¸ºæ­£ï¼‰
        Y_cam = (cY - cy) * avg_depth / fy  # ç›¸æœºåæ ‡ç³»Yè½´ï¼ˆä¸‹ä¸ºæ­£ï¼‰
        Z_cam = avg_depth                   # ç›¸æœºåæ ‡ç³»Zè½´ï¼ˆå‰ä¸ºæ­£ï¼Œä¸æ·±åº¦æ–¹å‘ä¸€è‡´ï¼‰

        # è¿”å›ç›¸æœºåæ ‡ç³»ä¸‹çš„3Dåæ ‡ï¼ˆæ ¼å¼ï¼š[X, Y, Z]ï¼‰
        return np.array([X_cam, Y_cam, Z_cam], dtype=np.float32)

    # æ¬§æ‹‰è§’è½¬æ—‹è½¬çŸ©é˜µï¼ˆä¸å˜ï¼‰
    def euler_to_rotation_matrix(self, rpy):
        roll, pitch, yaw = rpy
        R_x = np.array([[1, 0, 0], [0, math.cos(roll), -math.sin(roll)], [0, math.sin(roll), math.cos(roll)]])
        R_y = np.array([[math.cos(pitch), 0, math.sin(pitch)], [0, 1, 0], [-math.sin(pitch), 0, math.cos(pitch)]])
        R_z = np.array([[math.cos(yaw), -math.sin(yaw), 0], [math.sin(yaw), math.cos(yaw), 0], [0, 0, 1]])
        return np.dot(R_z, np.dot(R_y, R_x))

    # è·å–æœ«ç«¯åˆ°åŸºåº§çš„ä½å§¿ï¼ˆä¸å˜ï¼‰
    def get_end2base_pose(self):
        try:
            tcp_pose = self.robot.get_actual_tcp_pose()
            if not (-2 < tcp_pose[0] < 2 and -2 < tcp_pose[1] < 2 and -2 < tcp_pose[2] < 2):
                print("è­¦å‘Š: æœºæ¢°è‡‚ä½å§¿è¶…å‡ºåˆç†èŒƒå›´")
                return None

            x, y, z = tcp_pose[0], tcp_pose[1], tcp_pose[2]
            rx, ry, rz = tcp_pose[3], tcp_pose[4], tcp_pose[5]

            end2base = np.eye(4, dtype=np.float32)
            end2base[:3, :3] = self.euler_to_rotation_matrix([rx, ry, rz])
            end2base[:3, 3] = [x, y, z]
            return end2base
        except Exception as e:
            print(f"è·å–æœºæ¢°è‡‚ä½å§¿å‡ºé”™: {str(e)}")
            return None

    # è®¡ç®—åŸºåº§åæ ‡ç³»ä½å§¿ï¼ˆä¸å˜ï¼‰
    def calculate_robot_pose(self, target_center_2d, depth_image):
        # 1. è®¡ç®—ç›®æ ‡ä¸­å¿ƒç‚¹åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„3Dåæ ‡ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šå·²åœ¨get_obj2cam_poseä¸­ä¿å­˜æ·±åº¦å€¼ï¼‰
        center_in_cam = self.get_obj2cam_pose(target_center_2d, depth_image)
        if center_in_cam is None:
            self.last_robot_pose = None
            return None

        # 2. è·å–æœºæ¢°è‡‚æœ«ç«¯åˆ°åŸºåº§çš„ä½å§¿ï¼ˆåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
        end2base = self.get_end2base_pose()
        if end2base is None:
            self.last_robot_pose = None
            return None

        # 3. åæ ‡ç³»è½¬æ¢ï¼šç›¸æœºâ†’æœ«ç«¯â†’åŸºåº§ï¼ˆåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
        center_homogeneous = np.append(center_in_cam, 1.0)  # æ ¼å¼ï¼š[X, Y, Z, 1]
        center_in_end = self.end2cam @ center_homogeneous  # ç›¸æœºåæ ‡ç³» â†’ æœ«ç«¯åæ ‡ç³»
        center_in_base = end2base @ center_in_end          # æœ«ç«¯åæ ‡ç³» â†’ åŸºåº§åæ ‡ç³»

        # 4. æå–åŸºåº§åæ ‡ç³»ä¸‹çš„ä½ç½®å’Œå§¿æ€ï¼ˆå§¿æ€å¯æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼‰
        position = center_in_base[:3]  # åŸºåº§åæ ‡ç³»ä¸‹çš„3Dä½ç½®ï¼ˆX, Y, Zï¼‰
        orientation = [0, -180, 0]     # æ‰‹åŠ¨é…ç½®å§¿æ€ï¼ˆæ ¹æ®å®é™…æŠ“å–éœ€æ±‚è°ƒæ•´ï¼Œå•ä½ï¼šåº¦ï¼‰

        # 5. ä¿å­˜æœ€æ–°è§£ç®—ç»“æœ
        self.last_robot_pose = {
            "position": position,
            "orientation": orientation,
            "tcp_pose": self.robot.get_actual_tcp_pose() if self.robot else None
        }
        return self.last_robot_pose

    # å®‰å…¨æ ¡éªŒï¼ˆä¸å˜ï¼‰
    def check_safe_pose(self, modified_position, modified_orientation_rad):
        if modified_position is None or modified_orientation_rad is None:
            return False, "âŒ ä½å§¿æ•°æ®ä¸ºç©º"

        x, y, z = modified_position
        if not (self.SAFE_POSITION_RANGE["X"][0] <= x <= self.SAFE_POSITION_RANGE["X"][1]):
            msg = f"âŒ Xåæ ‡ {x:.4f}m è¶…å‡ºå®‰å…¨èŒƒå›´ [{self.SAFE_POSITION_RANGE['X'][0]:.4f}, {self.SAFE_POSITION_RANGE['X'][1]:.4f}]"
            return False, msg
        if not (self.SAFE_POSITION_RANGE["Y"][0] <= y <= self.SAFE_POSITION_RANGE["Y"][1]):
            msg = f"âŒ Yåæ ‡ {y:.4f}m è¶…å‡ºå®‰å…¨èŒƒå›´ [{self.SAFE_POSITION_RANGE['Y'][0]:.4f}, {self.SAFE_POSITION_RANGE['Y'][1]:.4f}]"
            return False, msg
        if not (self.SAFE_POSITION_RANGE["Z"][0] <= z <= self.SAFE_POSITION_RANGE["Z"][1]):
            msg = f"âŒ Zåæ ‡ {z:.4f}m è¶…å‡ºå®‰å…¨èŒƒå›´ [{self.SAFE_POSITION_RANGE['Z'][0]:.4f}, {self.SAFE_POSITION_RANGE['Z'][1]:.4f}]"
            return False, msg

        roll_deg = math.degrees(modified_orientation_rad[0])
        pitch_deg = math.degrees(modified_orientation_rad[1])
        yaw_deg = math.degrees(modified_orientation_rad[2])

        roll_min_deg = math.degrees(self.SAFE_ORIENTATION_RANGE["Roll"][0])
        roll_max_deg = math.degrees(self.SAFE_ORIENTATION_RANGE["Roll"][1])
        pitch_min_deg = math.degrees(self.SAFE_ORIENTATION_RANGE["Pitch"][0])
        pitch_max_deg = math.degrees(self.SAFE_ORIENTATION_RANGE["Pitch"][1])
        yaw_min_deg = math.degrees(self.SAFE_ORIENTATION_RANGE["Yaw"][0])
        yaw_max_deg = math.degrees(self.SAFE_ORIENTATION_RANGE["Yaw"][1])

        if not (roll_min_deg <= roll_deg <= roll_max_deg):
            msg = f"âŒ Rollè§’ {roll_deg:.2f}Â° è¶…å‡ºå®‰å…¨èŒƒå›´ [{roll_min_deg:.2f}, {roll_max_deg:.2f}]"
            return False, msg
        if not (pitch_min_deg <= pitch_deg <= pitch_max_deg):
            msg = f"âŒ Pitchè§’ {pitch_deg:.2f}Â° è¶…å‡ºå®‰å…¨èŒƒå›´ [{pitch_min_deg:.2f}, {pitch_max_deg:.2f}]"
            return False, msg
        if not (yaw_min_deg <= yaw_deg <= yaw_max_deg):
            msg = f"âŒ Yawè§’ {yaw_deg:.2f}Â° è¶…å‡ºå®‰å…¨èŒƒå›´ [{yaw_min_deg:.2f}, {yaw_max_deg:.2f}]"
            return False, msg

        msg = f"âœ… ä½å§¿å®‰å…¨ï¼šä½ç½®[{x:.4f},{y:.4f},{z:.4f}]m | å§¿æ€[{roll_deg:.2f},{pitch_deg:.2f},{yaw_deg:.2f}]Â°"
        return True, msg

    # ç”ŸæˆmoveLç›®æ ‡ä½å§¿ï¼ˆä¸å˜ï¼‰
    def generate_moveL_target(self, robot_pose):
        if robot_pose is None:
            return None

        # åŸºäºä¸­å¿ƒç‚¹åæ ‡è®¡ç®—ç›®æ ‡ä½å§¿ï¼ˆå åŠ åç§»é‡ï¼‰
        target_x = robot_pose["position"][0] + self.moveL_offset[0]
        target_y = robot_pose["position"][1] + self.moveL_offset[1]
        target_z = robot_pose["position"][2] + self.moveL_offset[2]

        target_roll = math.radians(robot_pose["orientation"][0] + self.moveL_offset[3])
        target_pitch = math.radians(robot_pose["orientation"][1] + self.moveL_offset[4])
        target_yaw = math.radians(robot_pose["orientation"][2] + self.moveL_offset[5])

        return [
            round(target_x, 4),
            round(target_y, 4),
            round(target_z, 4),
            round(target_roll, 4),
            round(target_pitch, 4),
            round(target_yaw, 4)
        ]

    # æ‰§è¡ŒmoveLè¿åŠ¨ï¼ˆä¸å˜ï¼‰
    def execute_moveL(self, robot_pose):
        if robot_pose is None:
            print("âŒ æ— æ³•æ‰§è¡ŒmoveLï¼šæœºå™¨äººä½å§¿ä¸ºç©º")
            return False

        moveL_target = self.generate_moveL_target(robot_pose)
        if moveL_target is None:
            print("âŒ æ— æ³•ç”ŸæˆmoveLç›®æ ‡ä½å§¿ï¼ˆæ— æœ‰æ•ˆç›®æ ‡ï¼‰")
            return False

        try:
            print("\n" + "=" * 60)
            print(f"ğŸ“¢ æ‰§è¡ŒmoveLè¿åŠ¨è‡³ç›®æ ‡ä¸­å¿ƒç‚¹ä½å§¿:")
            print(f"  X: {moveL_target[0]:.4f} m")
            print(f"  Y: {moveL_target[1]:.4f} m")
            print(f"  Z: {moveL_target[2]:.4f} m")
            print(f"  Roll: {math.degrees(moveL_target[3]):.2f}Â°")
            print(f"  Pitch: {math.degrees(moveL_target[4]):.2f}Â°")
            print(f"  Yaw: {math.degrees(moveL_target[5]):.2f}Â°")
            print(f"  è¿åŠ¨å‚æ•°: é€Ÿåº¦={self.moveL_speed}m/s, åŠ é€Ÿåº¦={self.moveL_acc}m/sÂ²")
            print("=" * 60)

            self.robot.moveL(
                target_pose=moveL_target,
                speed=self.moveL_speed,
                acceleration=self.moveL_acc
            )

            print("âœ… moveLè¿åŠ¨å®Œæˆ\n")
            return True
        except Exception as e:
            print(f"âŒ moveLè¿åŠ¨å¤±è´¥: {str(e)}")
            return False

    # -------------------------- å…³é”®ä¿®æ”¹2ï¼šç§»é™¤é»‘è‰²èƒŒæ™¯çŸ©å½¢+æ–°å¢æ·±åº¦ä¿¡æ¯æ˜¾ç¤º --------------------------
    def draw_pose_info(self, image, robot_pose, fps, target_center, moveL_status=None):
        # æ˜¾ç¤ºç±»åˆ«ä¿¡æ¯
        cv2.putText(image, f"Target Class: {self.target_class_id}", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

        # æ˜¾ç¤ºæ£€æµ‹çŠ¶æ€
        status_text = "Found Target" if self.found_target else "No Target"
        status_color = (0, 255, 0) if self.found_target else (0, 0, 255)
        cv2.putText(image, status_text, (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)

        # æ˜¾ç¤ºä¸­å¿ƒç‚¹åƒç´ åæ ‡
        if target_center is not None:
            cv2.putText(image, f"Center Pixel: ({target_center[0]}, {target_center[1]})",
                        (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
        else:
            cv2.putText(image, "Center Pixel: None", (10, 90),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)

        # -------------------------- æ–°å¢ï¼šå®æ—¶æ˜¾ç¤ºä¸­å¿ƒç‚¹æ·±åº¦ä¿¡æ¯ --------------------------
        depth_y = 120  # æ·±åº¦ä¿¡æ¯æ˜¾ç¤ºYåæ ‡ï¼ˆåœ¨ä¸­å¿ƒç‚¹åæ ‡ä¸‹æ–¹ï¼‰
        if self.last_center_depth is not None:
            # æ·±åº¦æœ‰æ•ˆï¼šæ˜¾ç¤ºç»¿è‰²æ–‡æœ¬
            cv2.putText(image, f"Center Depth: {self.last_center_depth:.4f} m",
                        (10, depth_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            # æ·±åº¦æ— æ•ˆï¼šæ˜¾ç¤ºçº¢è‰²æ–‡æœ¬
            cv2.putText(image, "Center Depth: Invalid", (10, depth_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # æ˜¾ç¤ºè§£ç®—åçš„ä¸­å¿ƒç‚¹6ä¸ªå‚æ•°ï¼ˆç§»é™¤é»‘è‰²èƒŒæ™¯çŸ©å½¢ï¼Œç›´æ¥ç»˜åˆ¶æ–‡æœ¬ï¼‰
        params_y = 150  # å‚æ•°æ˜¾ç¤ºèµ·å§‹Yåæ ‡ï¼ˆåœ¨æ·±åº¦ä¿¡æ¯ä¸‹æ–¹ï¼‰
        param_spacing = 25  # å‚æ•°è¡Œé—´è·

        # ç§»é™¤åŸé»‘è‰²èƒŒæ™¯çŸ©å½¢ä»£ç ï¼Œé¿å…é®æŒ¡å›¾åƒ
        if robot_pose is not None:
            # ä½ç½®å‚æ•° (X, Y, Z) - ç›®æ ‡ä¸­å¿ƒç‚¹åæ ‡ï¼ˆé’è‰²æ–‡æœ¬ï¼Œæé«˜å¯è¯»æ€§ï¼‰
            cv2.putText(image, f"X: {robot_pose['position'][0]:.4f} m",
                        (10, params_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.putText(image, f"Y: {robot_pose['position'][1]:.4f} m",
                        (10, params_y + param_spacing), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.putText(image, f"Z: {robot_pose['position'][2]:.4f} m",
                        (10, params_y + 2 * param_spacing), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)

            # å§¿æ€å‚æ•°ï¼ˆé»„è‰²æ–‡æœ¬ï¼‰
            cv2.putText(image, f"Roll: {robot_pose['orientation'][0]:.2f}Â°",
                        (10, params_y + 3 * param_spacing), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(image, f"Pitch: {robot_pose['orientation'][1]:.2f}Â°",
                        (10, params_y + 4 * param_spacing), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(image, f"Yaw: {robot_pose['orientation'][2]:.2f}Â°",
                        (10, params_y + 5 * param_spacing), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        else:
            cv2.putText(image, "No pose data available",
                        (10, params_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # æ˜¾ç¤ºmoveLçŠ¶æ€
        moveL_y = params_y + 6 * param_spacing
        if moveL_status is not None:
            moveL_text = "moveL: Running" if moveL_status == "running" else "moveL: Done"
            moveL_color = (0, 255, 255) if moveL_status == "running" else (0, 255, 0)
            cv2.putText(image, moveL_text, (10, moveL_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, moveL_color, 2)
        else:
            cv2.putText(image, "moveL: Ready", (10, moveL_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        # æ˜¾ç¤ºFPS
        cv2.putText(image, f"FPS: {fps:.1f}", (10, moveL_y + param_spacing),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        # æ“ä½œæç¤º
        cv2.putText(image, "Press 'n' to moveL | 's' to save | 'q' to quit",
                    (10, image.shape[0] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

        return image


def main():
    # é…ç½®å‚æ•°ï¼ˆæ ¹æ®å®é™…è·¯å¾„ä¿®æ”¹ï¼‰
    CAM2END_PATH = "cam2end_20251010_zhoutaobi.txt"
    CAMERA_PARAMS_PATH = "camera_20251010_zhoutaobi.ini"
    YOLO_MODEL_PATH = "seg_arm_body_20251010_zhoutaobi.pt"
    ROBOT_IP = "192.168.1.35"
    SAVE_DIR = "./yolo_robot_pose_results"
    TARGET_CLASS_ID = 1

    os.makedirs(SAVE_DIR, exist_ok=True)

    try:
        # åˆå§‹åŒ–æœºæ¢°è‡‚å’Œæ·±åº¦ç›¸æœº
        robot = UR_Robot(
            robot_ip=ROBOT_IP,
            gripper_port=False,
            is_use_robot=True,
            is_use_camera=True
        )
        camera = Camera(width=640, height=480, fps=30)  # Realsenseç›¸æœºï¼ˆéœ€ç¡®ä¿é©±åŠ¨æ­£å¸¸ï¼‰

        # åˆå§‹åŒ–è®¡ç®—å™¨
        calculator = YOLORobotPoseCalculator(
            cam2end_path=CAM2END_PATH,
            camera_params_path=CAMERA_PARAMS_PATH,
            yolo_model_path=YOLO_MODEL_PATH,
            robot=robot,
            camera=camera
        )
        calculator.target_class_id = TARGET_CLASS_ID  # è®¾ç½®ç›®æ ‡ç±»åˆ«

        # è°ƒæ•´è¿åŠ¨å‚æ•°ï¼ˆæ ¹æ®å®é™…éœ€æ±‚ä¿®æ”¹ï¼‰
        calculator.moveL_speed = 0.15
        calculator.moveL_acc = 0.15
        calculator.moveL_offset = [0, 0, 0.08, 0, 0, 0]  # ä½å§¿åç§»é‡ï¼ˆæ ¹æ®æŠ“å–éœ€æ±‚å¾®è°ƒï¼‰

        print("ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸï¼Œå¼€å§‹æ£€æµ‹...")
        print(f"ç›®æ ‡ç±»åˆ«ID: {TARGET_CLASS_ID}")
        print("=" * 60)
        print("æ“ä½œè¯´æ˜ï¼š")
        print("  - æŒ‰ 'n' é”®ï¼šæ‰§è¡ŒmoveLè¿åŠ¨åˆ°ç›®æ ‡ä¸­å¿ƒç‚¹")
        print("  - æŒ‰ 's' é”®ï¼šä¿å­˜å½“å‰å¸§æ•°æ®")
        print("  - æŒ‰ 'q' é”®ï¼šé€€å‡ºç¨‹åº")
        print("=" * 60 + "\n")

    except Exception as e:
        print(f"åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
        return

    frame_count = 0
    start_time = time.time()
    save_count = 0
    moveL_status = None

    # ä¸»å¾ªç¯ï¼ˆä¸å˜ï¼Œæ·±åº¦å€¼å·²åœ¨calculate_robot_poseä¸­è‡ªåŠ¨æ›´æ–°ï¼‰
    while True:
        # 1. è·å–æ·±åº¦ç›¸æœºæ•°æ®ï¼ˆcolorå›¾ç”¨äºæ£€æµ‹ï¼Œdepthå›¾ç”¨äºæ·±åº¦å€¼è·å–ï¼‰
        color_image, depth_image = camera.get_data()
        if color_image is None or depth_image is None:
            time.sleep(0.1)
            print("è­¦å‘Š: æœªè·å–åˆ°ç›¸æœºæ•°æ®ï¼Œé‡è¯•...")
            continue

        # 2. æ£€æµ‹ç›®æ ‡ï¼ˆåªè¿”å›å›¾åƒå’Œä¸­å¿ƒç‚¹2Dåæ ‡ï¼‰
        display_img, target_center = calculator.yolo_detect_target(color_image)

        # 3. è®¡ç®—ç›®æ ‡ä¸­å¿ƒç‚¹åœ¨åŸºåº§åæ ‡ç³»ä¸‹çš„ä½å§¿ï¼ˆä¼ å…¥ä¸­å¿ƒç‚¹+æ·±åº¦å›¾ï¼Œè‡ªåŠ¨æ›´æ–°æ·±åº¦å€¼ï¼‰
        robot_pose = None
        if target_center is not None:
            robot_pose = calculator.calculate_robot_pose(target_center, depth_image)
        else:
            print("æœªæ£€æµ‹åˆ°æœ‰æ•ˆç›®æ ‡ä¸­å¿ƒç‚¹ï¼Œæ— æ³•è®¡ç®—ä½å§¿")

        # 4. è®¡ç®—FPSå¹¶ç»˜åˆ¶ä¿¡æ¯ï¼ˆè‡ªåŠ¨æ˜¾ç¤ºæ·±åº¦å€¼ï¼‰
        frame_count += 1
        elapsed_time = time.time() - start_time
        fps = frame_count / elapsed_time if elapsed_time > 0 else 0
        display_img = calculator.draw_pose_info(display_img, robot_pose, fps, target_center, moveL_status)
        cv2.imshow("Detection + moveL Control (Depth-based)", display_img)

        # 5. é”®ç›˜äº‹ä»¶å¤„ç†ï¼ˆä¸å˜ï¼‰
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            print("\nç¨‹åºé€€å‡º")
            break
        elif key == ord('s'):
            save_count += 1
            timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            color_save_path = os.path.join(SAVE_DIR, f"color_{timestamp}_{save_count:03d}.jpg")
            cv2.imwrite(color_save_path, display_img)
            print(f"å·²ä¿å­˜ç¬¬{save_count}ç»„æ•°æ®: {color_save_path}")
        elif key == ord('n'):
            if robot_pose is None:
                print("âŒ æ— æ³•æ‰§è¡ŒmoveLï¼šæœªæ£€æµ‹åˆ°æœ‰æ•ˆç›®æ ‡ä½å§¿")
                continue

            # è¿åŠ¨å‰æ›´æ–°çŠ¶æ€å¹¶æ˜¾ç¤º
            moveL_status = "running"
            cv2.imshow("Detection + moveL Control (Depth-based)", display_img)
            cv2.waitKey(1)

            # è°ƒæ•´ç›®æ ‡ä½å§¿ï¼ˆæ ¹æ®å®é™…æŠ“å–éœ€æ±‚ä¿®æ”¹Zè½´é«˜åº¦å’Œå§¿æ€ï¼‰
            modified_robot_pose = {
                "position": robot_pose["position"].copy(),
                "orientation": robot_pose["orientation"].copy(),
                "tcp_pose": robot_pose["tcp_pose"]
            }
            modified_robot_pose["position"][2] = 0.4  # è°ƒæ•´æŠ“å–é«˜åº¦ï¼ˆé¿å…ç¢°æ’ï¼‰
            modified_robot_pose["orientation"] = [0, -180, 0]  # å›ºå®šå§¿æ€

            # å®‰å…¨æ ¡éªŒ
            modified_orientation_rad = [
                math.radians(modified_robot_pose["orientation"][0]),
                math.radians(modified_robot_pose["orientation"][1]),
                math.radians(modified_robot_pose["orientation"][2])
            ]
            is_safe, safe_msg = calculator.check_safe_pose(
                modified_position=modified_robot_pose["position"],
                modified_orientation_rad=modified_orientation_rad
            )
            print(safe_msg)

            if not is_safe:
                print("âŒ ä½å§¿ä¸å®‰å…¨ï¼Œå–æ¶ˆmoveLè¿åŠ¨")
                moveL_status = None
                continue

            # æ‰§è¡Œè¿åŠ¨
            success = calculator.execute_moveL(modified_robot_pose)
            moveL_status = "done" if success else None

    # é‡Šæ”¾èµ„æº
    cv2.destroyAllWindows()
    if hasattr(robot, 'rtde_c') and robot.rtde_c:
        robot.rtde_c.stopScript()


if __name__ == "__main__":
    main()