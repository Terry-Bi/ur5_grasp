import time
import os
import datetime
import cv2
import numpy as np
import math
import configparser
from ultralytics import YOLO
from ur5_robot_bsp import UR_Robot
from real.realsenseD415 import Camera


class EyeInHandPoseCalculator:
    def __init__(self, camera_params_path, cam2end_txt_path, yolo_model_path, robot, camera):
        # è®¾å¤‡å¯¹è±¡ï¼ˆç›¸æœºåˆšæ€§å›ºå®šåœ¨æœ«ç«¯ï¼Œå­˜åœ¨ç›¸å¯¹ä½ç½®ï¼‰
        self.robot = robot
        self.camera = camera  # Realsenseæ·±åº¦ç›¸æœº

        # è°ƒè¯•æ¨¡å¼ï¼ˆä¼˜å…ˆåˆå§‹åŒ–ï¼Œç¡®ä¿åŠ è½½å‚æ•°æ—¶å¯ç”¨ï¼‰
        self.debug = True

        # 1. åŠ è½½æ ¸å¿ƒæ ‡å®šå‚æ•°ï¼ˆç›¸æœºå†…å‚ + cam2endå˜æ¢çŸ©é˜µï¼‰
        self.camera_matrix, self.dist_coeffs = self.load_camera_params(camera_params_path)
        self.cam2end, self.end2cam = self.load_cam2end_from_txt(cam2end_txt_path)
        print("âœ… åŠ è½½å®Œæˆï¼šç›¸æœºå†…å‚ + ç›¸æœºâ†’æœ«ç«¯å˜æ¢çŸ©é˜µ(cam2end)")

        # 2. åŠ è½½YOLOç›®æ ‡æ£€æµ‹æ¨¡å‹
        self.yolo_model = YOLO(yolo_model_path)

        # 3. ç›®æ ‡æ£€æµ‹ä¸ä½å§¿è®¡ç®—é…ç½®
        self.target_class_id = 1  # ç›®æ ‡ç±»åˆ«IDï¼ˆéœ€ä¸YOLOè®­ç»ƒæ ‡ç­¾å¯¹åº”ï¼‰
        self.conf_threshold = 0.3  # æ£€æµ‹ç½®ä¿¡åº¦é˜ˆå€¼
        self.iou_threshold = 0.3  # IOUé˜ˆå€¼ï¼ˆè¿‡æ»¤é‡å¤æ£€æµ‹æ¡†ï¼‰
        self.depth_roi_size = 8  # æ·±åº¦é‡‡æ ·åŒºåŸŸå¤§å°ï¼ˆé™ä½å™ªå£°ï¼‰

        # 4. çŠ¶æ€å˜é‡ï¼ˆå®æ—¶æ›´æ–°ï¼‰
        self.found_target = False  # æ˜¯å¦æ£€æµ‹åˆ°ç›®æ ‡
        self.last_robot_pose = None  # æœ€è¿‘ä¸€æ¬¡è®¡ç®—çš„ç›®æ ‡åŸºåº§ä½å§¿
        self.last_center_depth = None  # æœ€è¿‘ä¸€æ¬¡ç›®æ ‡æ·±åº¦å€¼
        self.last_target_center = None  # æœ€è¿‘ä¸€æ¬¡ç›®æ ‡ä¸­å¿ƒç‚¹

        # 5. æœºæ¢°è‡‚è¿åŠ¨å®‰å…¨é…ç½®
        self.moveL_speed = 0.08  # ç›´çº¿è¿åŠ¨é€Ÿåº¦ï¼ˆm/sï¼‰
        self.moveL_acc = 0.08  # ç›´çº¿è¿åŠ¨åŠ é€Ÿåº¦ï¼ˆm/sÂ²ï¼‰
        self.moveL_offset = [0, 0, 0.05, 0, 0, 0]  # è¿åŠ¨åç§»ï¼ˆZè½´+5cmé¿å…ç¢°æ’ï¼‰
        # å®‰å…¨ä½ç½®èŒƒå›´ï¼ˆæ ¹æ®å®é™…æœºæ¢°è‡‚å·¥ä½œç©ºé—´è°ƒæ•´ï¼ï¼‰
        self.SAFE_POSITION_RANGE = {
            "X": [-100, 100],
            "Y": [-100, 100],
            "Z": [-100, 100]
        }
        # å®‰å…¨å§¿æ€èŒƒå›´ï¼ˆæ¬§æ‹‰è§’ï¼Œå•ä½ï¼šå¼§åº¦ï¼‰
        self.SAFE_ORIENTATION_RANGE = {
            "Roll": [-math.pi, math.pi],
            "Pitch": [-math.pi, math.pi],
            "Yaw": [-math.pi, math.pi]
        }

        # 6. å¯è§†åŒ–é…ç½®
        self.center_outer_radius = 10  # ä¸­å¿ƒç‚¹å¤–åœ†åŠå¾„
        self.center_inner_radius = 3  # ä¸­å¿ƒç‚¹å†…åœ†åŠå¾„
        self.center_outer_color = (0, 0, 0)  # å¤–åœ†é¢œè‰²ï¼ˆé»‘è‰²ï¼‰
        self.center_inner_color = (0, 255, 255)  # å†…åœ†é¢œè‰²ï¼ˆé»„è‰²ï¼‰
        self.center_outer_thickness = 2  # å¤–åœ†çº¿å®½
        self.center_inner_thickness = -1  # å†…åœ†å¡«å……ï¼ˆ-1è¡¨ç¤ºå¡«å……ï¼‰

    """
    1. åŠ è½½ç›¸æœºå†…å‚ï¼ˆé€‚é…è‡ªå®šä¹‰INIæ ¼å¼ï¼š[camera_parameters] + [distortion_parameters]ï¼‰
    """

    def load_camera_params(self, file_path):
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"ç›¸æœºå†…å‚æ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")

        config = configparser.ConfigParser()
        config.read(file_path, encoding="utf-8")

        # è¯»å–å†…å‚ï¼ˆä¸ä½ çš„INIèŠ‚ååŒ¹é…ï¼‰
        fx = float(config.get('camera_parameters', 'fx'))
        fy = float(config.get('camera_parameters', 'fy'))
        cx = float(config.get('camera_parameters', 'cx'))
        cy = float(config.get('camera_parameters', 'cy'))
        camera_matrix = np.array([[fx, 0, cx],
                                  [0, fy, cy],
                                  [0, 0, 1]], dtype=np.float32)

        # è¯»å–ç•¸å˜ç³»æ•°ï¼ˆä¸ä½ çš„INIèŠ‚ååŒ¹é…ï¼‰
        k1 = float(config.get('distortion_parameters', 'k1', fallback=0.0))
        k2 = float(config.get('distortion_parameters', 'k2', fallback=0.0))
        p1 = float(config.get('distortion_parameters', 'p1', fallback=0.0))
        p2 = float(config.get('distortion_parameters', 'p2', fallback=0.0))
        k3 = float(config.get('distortion_parameters', 'k3', fallback=0.0))
        dist_coeffs = np.array([[k1, k2, p1, p2, k3]], dtype=np.float32)

        if self.debug:
            print(f"ğŸ“· ç›¸æœºå†…å‚çŸ©é˜µ:\n{camera_matrix}")
            print(f"ğŸ“· ç•¸å˜ç³»æ•°: {dist_coeffs}")
        return camera_matrix, dist_coeffs

    """
    2. åŠ è½½cam2endçŸ©é˜µï¼ˆç›¸æœºâ†’æœ«ç«¯çš„å›ºå®šå®‰è£…ä½å§¿ï¼Œä»TXTè¯»å–4x4é½æ¬¡çŸ©é˜µï¼‰
    """

    def load_cam2end_from_txt(self, file_path):
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"cam2endçŸ©é˜µæ–‡ä»¶ä¸å­˜åœ¨ï¼š{file_path}")

        # è¯»å–4x4çŸ©é˜µï¼ˆæ¯è¡Œ4ä¸ªæ•°å­—ï¼Œå…±4è¡Œï¼‰
        cam2end = []
        with open(file_path, 'r') as f:
            for line_num in range(4):
                line = f.readline().strip()
                if not line:
                    raise ValueError(f"cam2endæ–‡ä»¶ç¬¬{line_num + 1}è¡Œä¸ºç©ºï¼Œæ ¼å¼é”™è¯¯")
                elements = list(map(float, line.split()))
                if len(elements) != 4:
                    raise ValueError(f"cam2endæ–‡ä»¶ç¬¬{line_num + 1}è¡Œéœ€4ä¸ªå…ƒç´ ï¼Œå®é™…{len(elements)}ä¸ª")
                cam2end.append(elements)

        cam2end = np.array(cam2end, dtype=np.float32)
        # æ ¡éªŒé½æ¬¡çŸ©é˜µåˆæ³•æ€§ï¼ˆæœ€åä¸€è¡Œå¿…é¡»æ˜¯[0,0,0,1]ï¼‰
        if not np.allclose(cam2end[3], [0.0, 0.0, 0.0, 1.0], atol=1e-3):
            raise ValueError(f"cam2endçŸ©é˜µéæ³•ï¼æœ€åä¸€è¡Œåº”ä¸º[0,0,0,1]ï¼Œå®é™…ä¸º{cam2end[3]}")

        # è®¡ç®—æœ«ç«¯â†’ç›¸æœºçš„é€†çŸ©é˜µï¼ˆå¤‡ç”¨ï¼‰
        end2cam = np.linalg.inv(cam2end)

        if self.debug:
            print(f"ğŸ”— ç›¸æœºâ†’æœ«ç«¯å˜æ¢çŸ©é˜µ(cam2end):\n{cam2end}")
            print(f"ğŸ”— æœ«ç«¯â†’ç›¸æœºå˜æ¢çŸ©é˜µ(end2cam):\n{end2cam}")
        return cam2end, end2cam

    """
    3. YOLOç›®æ ‡æ£€æµ‹ï¼ˆè¾“å‡ºç›®æ ‡ä¸­å¿ƒç‚¹+å¯è§†åŒ–æ ‡æ³¨ï¼‰
    """

    def yolo_detect_target(self, color_image):
        display_img = color_image.copy()
        target_center = None
        self.found_target = False

        try:
            # YOLOæ¨ç†ï¼ˆé™é»˜æ¨¡å¼ï¼‰
            results = self.yolo_model(
                color_image,
                conf=self.conf_threshold,
                iou=self.iou_threshold,
                verbose=False,
                imgsz=640
            )
            result = results[0]

            # ä¼˜å…ˆä½¿ç”¨è¯­ä¹‰åˆ†å‰²æ©ç ï¼ˆæ›´ç²¾å‡†çš„ä¸­å¿ƒç‚¹è®¡ç®—ï¼‰
            if result.masks is not None:
                # éå†æ‰€æœ‰æ£€æµ‹ç»“æœï¼Œç­›é€‰ç›®æ ‡ç±»åˆ«
                for idx, (mask, cls, conf) in enumerate(zip(result.masks.data, result.boxes.cls, result.boxes.conf)):
                    cls_id = int(cls)
                    confidence = float(conf)
                    if cls_id != self.target_class_id:
                        continue
                    self.found_target = True

                    # æ©ç åå¤„ç†ï¼ˆé€‚é…åŸå›¾å°ºå¯¸ï¼‰
                    mask_np = mask.cpu().numpy().astype(np.uint8) * 255
                    if mask_np.shape != (color_image.shape[0], color_image.shape[1]):
                        mask_np = cv2.resize(mask_np, (color_image.shape[1], color_image.shape[0]))

                    # å¯è§†åŒ–ï¼šåŠé€æ˜æ©ç 
                    mask_3d = np.stack([mask_np] * 3, axis=-1) / 255.0
                    display_img = cv2.addWeighted(display_img, 0.7, (mask_3d * (0, 255, 0)).astype(np.uint8), 0.3, 0)

                    # å¯è§†åŒ–ï¼šè¾¹ç•Œæ¡†+ç½®ä¿¡åº¦
                    x1, y1, x2, y2 = result.boxes.xyxy[idx].cpu().numpy()
                    cv2.rectangle(display_img, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                    cv2.putText(display_img, f"Cls:{cls_id} (Conf:{confidence:.2f})",
                                (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

                    # è®¡ç®—æ©ç çš„ä¸­å¿ƒï¼ˆè½®å»“çŸ©æ–¹æ³•ï¼ŒæŠ—åç§»ï¼‰
                    contours, _ = cv2.findContours(mask_np, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    if contours:
                        largest_contour = max(contours, key=cv2.contourArea)
                        M = cv2.moments(largest_contour)
                        if M["m00"] > 0:  # é¿å…é™¤ä»¥0ï¼ˆè½®å»“é¢ç§¯ä¸ä¸º0ï¼‰
                            cX = int(M["m10"] / M["m00"])
                            cY = int(M["m01"] / M["m00"])
                            target_center = (cX, cY)
                            self.last_target_center = target_center  # å®æ—¶æ›´æ–°ä¸­å¿ƒç‚¹

                            # å¯è§†åŒ–ï¼šä¸­å¿ƒç‚¹åŒåœ†æ ‡è®°
                            cv2.circle(display_img, (cX, cY), self.center_outer_radius,
                                       self.center_outer_color, self.center_outer_thickness)
                            cv2.circle(display_img, (cX, cY), self.center_inner_radius,
                                       self.center_inner_color, self.center_inner_thickness)
                            cv2.putText(display_img, f"Center:({cX},{cY})",
                                        (cX + 15, cY - 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            # è‹¥æ— æ©ç ï¼ˆä»…ç›®æ ‡æ£€æµ‹æ¡†ï¼‰ï¼Œç”¨æ¡†ä¸­å¿ƒè¿‘ä¼¼
            elif result.boxes is not None and len(result.boxes) > 0:
                for idx, (box, cls, conf) in enumerate(zip(result.boxes.xyxy, result.boxes.cls, result.boxes.conf)):
                    cls_id = int(cls)
                    confidence = float(conf)
                    if cls_id != self.target_class_id:
                        continue
                    self.found_target = True
                    x1, y1, x2, y2 = box.cpu().numpy()
                    cX = int((x1 + x2) / 2)
                    cY = int((y1 + y2) / 2)
                    target_center = (cX, cY)
                    self.last_target_center = target_center

                    # å¯è§†åŒ–ï¼šè¾¹ç•Œæ¡†+ä¸­å¿ƒç‚¹
                    cv2.rectangle(display_img, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                    cv2.circle(display_img, (cX, cY), self.center_outer_radius,
                               self.center_outer_color, self.center_outer_thickness)
                    cv2.circle(display_img, (cX, cY), self.center_inner_radius,
                               self.center_inner_color, self.center_inner_thickness)

        except Exception as e:
            print(f"âŒ ç›®æ ‡æ£€æµ‹å‡ºé”™: {str(e)}")
        return display_img, target_center

    """
    4. å…³é”®ä¿®å¤1ï¼šç›®æ ‡â†’ç›¸æœºåæ ‡ç³»ï¼ˆä¿®æ­£ç›¸æœºæ–¹å‘ï¼Œè¾“å‡ºé½æ¬¡åæ ‡ï¼‰
    """

    def get_obj2cam_pose(self, target_center_2d, depth_image):
        if target_center_2d is None or depth_image is None:
            print("âš ï¸  ä¸­å¿ƒç‚¹æˆ–æ·±åº¦å›¾ä¸ºç©ºï¼Œæ— æ³•è®¡ç®—ç›¸æœºåæ ‡")
            self.last_center_depth = None
            return None

        cX, cY = target_center_2d
        fx, fy = self.camera_matrix[0, 0], self.camera_matrix[1, 1]
        cx, cy = self.camera_matrix[0, 2], self.camera_matrix[1, 2]

        # æ­¥éª¤1ï¼šæ·±åº¦é‡‡æ ·ï¼ˆROIåŒºåŸŸæ»¤æ³¢ï¼Œé™ä½å™ªå£°ï¼‰
        half_roi = self.depth_roi_size // 2
        depth_h, depth_w = depth_image.shape
        # ç¡®ä¿ROIä¸è¶…å‡ºå›¾åƒè¾¹ç•Œ
        start_x = max(0, cX - half_roi)
        end_x = min(depth_w, cX + half_roi + 1)
        start_y = max(0, cY - half_roi)
        end_y = min(depth_h, cY + half_roi + 1)
        depth_roi = depth_image[start_y:end_y, start_x:end_x]

        # æ­¥éª¤2ï¼šè¿‡æ»¤æ— æ•ˆæ·±åº¦ï¼ˆRealsenseæ— æ•ˆæ·±åº¦ä¸º0ï¼‰
        valid_depth = depth_roi[depth_roi > 10]  # è¿‡æ»¤å°äº10mmçš„å™ªå£°
        if len(valid_depth) < 3:  # è‡³å°‘3ä¸ªæœ‰æ•ˆç‚¹æ‰å¯ä¿¡
            print(f"âš ï¸  ä¸­å¿ƒç‚¹({cX},{cY})æœ‰æ•ˆæ·±åº¦ç‚¹ä¸è¶³ï¼ˆä»…{len(valid_depth)}ä¸ªï¼‰")
            self.last_center_depth = None
            return None

        # æ­¥éª¤3ï¼šæ·±åº¦å€¼ä¼˜åŒ–ï¼ˆä¸­ä½æ•°æ»¤æ³¢æŠ— outliersï¼‰
        avg_depth = np.median(valid_depth) / 1000.0  # mm â†’ m
        self.last_center_depth = round(avg_depth, 4)

        # æ­¥éª¤4ï¼šç›¸æœºåæ ‡ç³»è®¡ç®—ï¼ˆä¿®æ­£æ–¹å‘ï¼šRealsense Yä¸‹â†’æœºæ¢°è‡‚Yä¸Šï¼ŒZå‰â†’Zå‰ï¼‰
        X_cam = (cX - cx) * avg_depth / fx  # ç›¸æœºXï¼ˆå³ï¼‰â†’ æœºæ¢°è‡‚Xï¼ˆå³ï¼‰ï¼šä¸€è‡´
        Y_cam = -(cY - cy) * avg_depth / fy  # ç›¸æœºYï¼ˆä¸‹ï¼‰â†’ æœºæ¢°è‡‚Yï¼ˆä¸Šï¼‰ï¼šå–åï¼ˆå…³é”®ä¿®æ­£ï¼ï¼‰
        Z_cam = avg_depth  # ç›¸æœºZï¼ˆå‰ï¼‰â†’ æœºæ¢°è‡‚Zï¼ˆä¸Šï¼‰ï¼šéœ€æ ¹æ®å®‰è£…æ–¹å‘è°ƒæ•´ï¼ˆè‹¥å€’ç½®åˆ™å–åï¼‰

        # è¾“å‡ºé½æ¬¡åæ ‡ï¼ˆ4x1ï¼‰ï¼Œæ–¹ä¾¿åç»­çŸ©é˜µè¿ç®—
        obj_in_cam_hom = np.array([X_cam, Y_cam, Z_cam, 1.0], dtype=np.float32).reshape(4, 1)

        if self.debug:
            print(f"\nğŸ“ ç›¸æœºåæ ‡ç³»ç›®æ ‡åæ ‡: X={X_cam:.4f}m, Y={Y_cam:.4f}m, Z={Z_cam:.4f}m")
            print(f"ğŸ“ ç›®æ ‡æ·±åº¦: {self.last_center_depth:.4f}m")
        return obj_in_cam_hom

    """
    5. å…³é”®ä¿®å¤2ï¼šç›¸æœºâ†’æœ«ç«¯åæ ‡ç³»ï¼ˆç”¨cam2endçŸ©é˜µåŠ¨æ€è½¬æ¢ï¼‰
    """

    def transform_cam2end(self, obj_in_cam_hom):
        if obj_in_cam_hom is None:
            print("âš ï¸  ç›¸æœºåæ ‡ä¸ºç©ºï¼Œæ— æ³•è½¬æ¢åˆ°æœ«ç«¯åæ ‡")
            return None

        # æ ¸å¿ƒï¼šç›¸æœºâ†’æœ«ç«¯çš„é½æ¬¡å˜æ¢ï¼ˆcam2endæ˜¯ç›¸æœºç›¸å¯¹äºæœ«ç«¯çš„å®‰è£…ä½å§¿ï¼‰
        # å…¬å¼ï¼šobj_end = cam2end * obj_camï¼ˆçŸ©é˜µä¹˜æ³•é¡ºåºä¸èƒ½é”™ï¼ï¼‰
        obj_in_end_hom = np.dot(self.cam2end, obj_in_cam_hom)

        # æå–3Dåæ ‡ï¼ˆå‰3ä¸ªå…ƒç´ ï¼‰
        obj_in_end = obj_in_end_hom[:3].flatten()  # è½¬ä¸º1Dæ•°ç»„ï¼ˆX,Y,Zï¼‰

        if self.debug:
            print(f"ğŸ”„ æœ«ç«¯åæ ‡ç³»ç›®æ ‡åæ ‡: X={obj_in_end[0]:.4f}m, Y={obj_in_end[1]:.4f}m, Z={obj_in_end[2]:.4f}m")
        return obj_in_end

    """
    6. å…³é”®ä¿®å¤3ï¼šæœ«ç«¯â†’åŸºåº§åæ ‡ç³»ï¼ˆå®æ—¶è¯»å–æœ«ç«¯ä½å§¿ï¼ŒåŠ¨æ€è®¡ç®—ï¼‰
    """

    def get_end2base_pose(self):
        try:
            # å®æ—¶è¯»å–UR5æœ«ç«¯TCPä½å§¿ï¼ˆ[X,Y,Z,Roll,Pitch,Yaw]ï¼Œå•ä½ï¼šm/å¼§åº¦ï¼‰
            tcp_pose = self.robot.get_actual_tcp_pose()
            if tcp_pose is None or len(tcp_pose) != 6:
                print("âš ï¸  æœªè·å–åˆ°æœ‰æ•ˆæœ«ç«¯TCPä½å§¿ï¼ˆéœ€6ä¸ªå‚æ•°ï¼šX,Y,Z,Roll,Pitch,Yawï¼‰")
                return None

            x_end, y_end, z_end = tcp_pose[0], tcp_pose[1], tcp_pose[2]
            roll_end, pitch_end, yaw_end = tcp_pose[3], tcp_pose[4], tcp_pose[5]

            # å®‰å…¨æ ¡éªŒï¼šæœ«ç«¯æ˜¯å¦åœ¨å·¥ä½œç©ºé—´å†…
            if not (self.SAFE_POSITION_RANGE["X"][0] <= x_end <= self.SAFE_POSITION_RANGE["X"][1] and
                    self.SAFE_POSITION_RANGE["Y"][0] <= y_end <= self.SAFE_POSITION_RANGE["Y"][1] and
                    self.SAFE_POSITION_RANGE["Z"][0] <= z_end <= self.SAFE_POSITION_RANGE["Z"][1]):
                print(f"âš ï¸  æœ«ç«¯è¶…å‡ºå®‰å…¨èŒƒå›´: X={x_end:.4f}, Y={y_end:.4f}, Z={z_end:.4f}")
                return None

            # æ„å»ºæœ«ç«¯â†’åŸºåº§çš„4x4é½æ¬¡å˜æ¢çŸ©é˜µï¼ˆURæœºæ¢°è‡‚é»˜è®¤Z-Y-Xæ¬§æ‹‰è§’é¡ºåºï¼‰
            end2base = np.eye(4, dtype=np.float32)

            # 1. æ—‹è½¬çŸ©é˜µï¼ˆZ-Y-Xé¡ºåºï¼‰
            # Yawï¼ˆç»•Zè½´ï¼‰
            Rz = np.array([[math.cos(yaw_end), -math.sin(yaw_end), 0],
                           [math.sin(yaw_end), math.cos(yaw_end), 0],
                           [0, 0, 1]], dtype=np.float32)
            # Pitchï¼ˆç»•Yè½´ï¼‰
            Ry = np.array([[math.cos(pitch_end), 0, math.sin(pitch_end)],
                           [0, 1, 0],
                           [-math.sin(pitch_end), 0, math.cos(pitch_end)]], dtype=np.float32)
            # Rollï¼ˆç»•Xè½´ï¼‰
            Rx = np.array([[1, 0, 0],
                           [0, math.cos(roll_end), -math.sin(roll_end)],
                           [0, math.sin(roll_end), math.cos(roll_end)]], dtype=np.float32)
            # ç»„åˆæ—‹è½¬çŸ©é˜µï¼ˆZâ†’Yâ†’Xé¡ºåºï¼ŒçŸ©é˜µä¹˜æ³•é¡ºåºä¸º Rz*Ry*Rxï¼‰
            end2base[:3, :3] = np.dot(Rz, np.dot(Ry, Rx))

            # 2. å¹³ç§»å‘é‡ï¼ˆæœ«ç«¯åœ¨åŸºåº§åæ ‡ç³»çš„ä½ç½®ï¼‰
            end2base[:3, 3] = [x_end, y_end, z_end]

            if self.debug:
                print(f"\nğŸ¤– æœ«ç«¯å®æ—¶ä½å§¿ï¼ˆåŸºåº§åæ ‡ç³»ï¼‰:")
                print(f"   ä½ç½®: X={x_end:.4f}m, Y={y_end:.4f}m, Z={z_end:.4f}m")
                print(
                    f"   å§¿æ€: Roll={math.degrees(roll_end):.2f}Â°, Pitch={math.degrees(pitch_end):.2f}Â°, Yaw={math.degrees(yaw_end):.2f}Â°")

            return end2base

        except Exception as e:
            print(f"âŒ è·å–æœ«ç«¯ä½å§¿å‡ºé”™: {str(e)}")
            return None

    """
    7. æ ¸å¿ƒä¿®å¤ï¼šç›®æ ‡åŸºåº§ä½å§¿è®¡ç®—ï¼ˆå®Œæ•´åŠ¨æ€é“¾è·¯ï¼‰
    æµç¨‹ï¼šç›®æ ‡åƒç´  â†’ ç›¸æœºé½æ¬¡åæ ‡ â†’ æœ«ç«¯3Dåæ ‡ â†’ æœ«ç«¯åŸºåº§çŸ©é˜µ â†’ ç›®æ ‡åŸºåº§åæ ‡
    """

    def calculate_robot_pose(self, target_center_2d, depth_image):
        # æ­¥éª¤1ï¼šç›®æ ‡â†’ç›¸æœºé½æ¬¡åæ ‡ï¼ˆä¿®æ­£æ–¹å‘ï¼‰
        obj_in_cam_hom = self.get_obj2cam_pose(target_center_2d, depth_image)
        if obj_in_cam_hom is None:
            self.last_robot_pose = None
            return None

        # æ­¥éª¤2ï¼šç›¸æœºâ†’æœ«ç«¯3Dåæ ‡ï¼ˆç”¨cam2endçŸ©é˜µï¼‰
        obj_in_end = self.transform_cam2end(obj_in_cam_hom)
        if obj_in_end is None:
            self.last_robot_pose = None
            return None

        # æ­¥éª¤3ï¼šè·å–æœ«ç«¯â†’åŸºåº§å®æ—¶å˜æ¢çŸ©é˜µ
        end2base = self.get_end2base_pose()
        if end2base is None:
            self.last_robot_pose = None
            return None

        # æ­¥éª¤4ï¼šç›®æ ‡â†’åŸºåº§åæ ‡ç³»ï¼ˆæ ¸å¿ƒåŠ¨æ€è®¡ç®—ï¼‰
        try:
            # å°†æœ«ç«¯åæ ‡ç³»çš„ç›®æ ‡åæ ‡è½¬ä¸ºé½æ¬¡åæ ‡ï¼ˆ4x1ï¼‰
            obj_in_end_hom = np.array([obj_in_end[0], obj_in_end[1], obj_in_end[2], 1.0], dtype=np.float32).reshape(4,
                                                                                                                    1)

            # æ ¸å¿ƒå…¬å¼ï¼šç›®æ ‡åŸºåº§åæ ‡ = æœ«ç«¯åŸºåº§çŸ©é˜µ * ç›®æ ‡æœ«ç«¯åæ ‡
            obj_in_base_hom = np.dot(end2base, obj_in_end_hom)
            obj_in_base = obj_in_base_hom[:3].flatten()  # æå–3Dåæ ‡ï¼ˆX,Y,Zï¼‰

            # æ‰‹åŠ¨æ ¡å‡†åç§»ï¼ˆéœ€æ›¿æ¢ä¸ºå®é™…æµ‹é‡çš„Î”x, Î”y, Î”zï¼‰
            delta_x = -26.08124  # ç¤ºä¾‹ï¼šxæ–¹å‘è¡¥å¿0.02m
            delta_y = -5.3292  # ç¤ºä¾‹ï¼šyæ–¹å‘è¡¥å¿-0.01m
            delta_z = -13.5320  # ç¤ºä¾‹ï¼šzæ–¹å‘è¡¥å¿0.03m

            obj_in_base[0] += delta_x
            obj_in_base[1] += delta_y
            obj_in_base[2] += delta_z


            # ç›®æ ‡å§¿æ€ï¼šæ ¹æ®æŠ“å–éœ€æ±‚è®¾ç½®ï¼ˆç¤ºä¾‹ï¼šå¸ç›˜æœä¸‹ï¼Œä¸æœ«ç«¯å§¿æ€ä¸€è‡´ï¼‰
            # è‹¥éœ€è‡ªå®šä¹‰å§¿æ€ï¼Œå¯ä¿®æ”¹æ­¤å¤„ï¼ˆå¦‚ï¼š[0, math.pi, 0] è¡¨ç¤ºPitch=180Â°ï¼‰
            target_orientation = [0.0, math.pi, 0.0]  # å¼§åº¦å•ä½
            target_orientation_deg = [math.degrees(ang) for ang in target_orientation]

            # è°ƒè¯•æ—¥å¿—ï¼šå®æ—¶æ‰“å°ç›®æ ‡åŸºåº§ä½å§¿ï¼ˆéªŒè¯æ˜¯å¦å˜åŒ–ï¼‰
            if self.debug:
                print(f"\nğŸ¯ ç›®æ ‡å®æ—¶åŸºåº§ä½å§¿:")
                print(f"   ä½ç½®: X={obj_in_base[0]:.4f}m, Y={obj_in_base[1]:.4f}m, Z={obj_in_base[2]:.4f}m")
                print(
                    f"   å§¿æ€: Roll={target_orientation_deg[0]:.2f}Â°, Pitch={target_orientation_deg[1]:.2f}Â°, Yaw={target_orientation_deg[2]:.2f}Â°")

            # ä¿å­˜å®æ—¶ä½å§¿
            self.last_robot_pose = {
                "position": obj_in_base,
                "orientation": target_orientation,
                "tcp_pose": self.robot.get_actual_tcp_pose() if self.robot else None
            }
            return self.last_robot_pose

        except Exception as e:
            print(f"âŒ ç›®æ ‡åŸºåº§ä½å§¿è®¡ç®—å‡ºé”™: {str(e)}")
            self.last_robot_pose = None
            return None

    """
    8. æœºæ¢°è‡‚è¿åŠ¨å®‰å…¨æ ¡éªŒï¼ˆä¸å˜ï¼‰
    """

    def check_safe_pose(self, modified_position, modified_orientation):
        if modified_position is None or modified_orientation is None:
            return False, "âŒ ä½å§¿æ•°æ®ä¸ºç©º"

        x, y, z = modified_position
        # ä½ç½®å®‰å…¨æ ¡éªŒ
        if not (self.SAFE_POSITION_RANGE["X"][0] <= x <= self.SAFE_POSITION_RANGE["X"][1]):
            return False, f"âŒ Xè¶…å‡ºèŒƒå›´[{self.SAFE_POSITION_RANGE['X'][0]},{self.SAFE_POSITION_RANGE['X'][1]}]"
        if not (self.SAFE_POSITION_RANGE["Y"][0] <= y <= self.SAFE_POSITION_RANGE["Y"][1]):
            return False, f"âŒ Yè¶…å‡ºèŒƒå›´[{self.SAFE_POSITION_RANGE['Y'][0]},{self.SAFE_POSITION_RANGE['Y'][1]}]"
        if not (self.SAFE_POSITION_RANGE["Z"][0] <= z <= self.SAFE_POSITION_RANGE["Z"][1]):
            return False, f"âŒ Zè¶…å‡ºèŒƒå›´[{self.SAFE_POSITION_RANGE['Z'][0]},{self.SAFE_POSITION_RANGE['Z'][1]}]"

        # å§¿æ€å®‰å…¨æ ¡éªŒ
        roll, pitch, yaw = modified_orientation
        if not (self.SAFE_ORIENTATION_RANGE["Roll"][0] <= roll <= self.SAFE_ORIENTATION_RANGE["Roll"][1]):
            return False, f"âŒ Rollè§’è¶…å‡ºå®‰å…¨èŒƒå›´"
        if not (self.SAFE_ORIENTATION_RANGE["Pitch"][0] <= pitch <= self.SAFE_ORIENTATION_RANGE["Pitch"][1]):
            return False, f"âŒ Pitchè§’è¶…å‡ºå®‰å…¨èŒƒå›´"
        if not (self.SAFE_ORIENTATION_RANGE["Yaw"][0] <= yaw <= self.SAFE_ORIENTATION_RANGE["Yaw"][1]):
            return False, f"âŒ Yawè§’è¶…å‡ºå®‰å…¨èŒƒå›´"

        # è·ç¦»å®‰å…¨æ ¡éªŒï¼ˆç›®æ ‡ä¸ç›¸æœºè¿‡è¿‘ï¼‰
        if self.last_center_depth is not None:
            safe_distance = 0.10
            if self.last_center_depth < safe_distance:
                return False, f"âŒ ç›®æ ‡ä¸ç›¸æœºè¿‡è¿‘ï¼Œå½“å‰è·ç¦»{self.last_center_depth:.2f}mï¼Œå®‰å…¨è·ç¦»{safe_distance}m"

        return True, f"âœ… ä½å§¿å®‰å…¨ï¼šX={x:.4f}, Y={y:.4f}, Z={z:.4f} | Roll={math.degrees(roll):.2f}Â°, Pitch={math.degrees(pitch):.2f}Â°, Yaw={math.degrees(yaw):.2f}Â°"
    """
    9. ç”ŸæˆmoveLç›®æ ‡ä½å§¿ï¼ˆä¸å˜ï¼‰
    """

    def generate_moveL_target(self, robot_pose):
        if robot_pose is None:
            print("âš ï¸  ç›®æ ‡ä½å§¿ä¸ºç©ºï¼Œæ— æ³•ç”ŸæˆmoveLç›®æ ‡")
            return None

        # å åŠ åç§»é‡ï¼ˆé¿å…ç¢°æ’ï¼‰
        target_x = robot_pose["position"][0] + self.moveL_offset[0]
        target_y = robot_pose["position"][1] + self.moveL_offset[1]
        target_z = robot_pose["position"][2] + self.moveL_offset[2]
        target_roll = robot_pose["orientation"][0] + math.radians(self.moveL_offset[3])
        target_pitch = robot_pose["orientation"][1] + math.radians(self.moveL_offset[4])
        target_yaw = robot_pose["orientation"][2] + math.radians(self.moveL_offset[5])

        # å››èˆäº”å…¥ï¼ˆæœºæ¢°è‡‚æ¥æ”¶ç²¾åº¦æœ‰é™ï¼‰
        return [
            round(target_x, 4), round(target_y, 4), round(target_z, 4),
            round(target_roll, 4), round(target_pitch, 4), round(target_yaw, 4)
        ]

    """
    10. æ‰§è¡ŒmoveLè¿åŠ¨ï¼ˆä¸å˜ï¼‰
    """

    def execute_moveL(self, robot_pose):
        if robot_pose is None:
            print("âŒ ç›®æ ‡ä½å§¿ä¸ºç©ºï¼Œæ— æ³•æ‰§è¡ŒmoveL")
            return False

        moveL_target = self.generate_moveL_target(robot_pose)
        if moveL_target is None:
            print("âŒ æ— æ³•ç”ŸæˆmoveLç›®æ ‡ä½å§¿")
            return False

        # å®‰å…¨æ ¡éªŒ
        is_safe, safe_msg = self.check_safe_pose(moveL_target[:3], moveL_target[3:])
        print(f"\n{safe_msg}")
        if not is_safe:
            return False

        # æ‰§è¡Œè¿åŠ¨
        try:
            print("\n" + "=" * 70)
            print("âš ï¸  æ‰§è¡ŒmoveLè¿åŠ¨ï¼ˆå®‰å…¨ç¬¬ä¸€ï¼ï¼‰")
            print(f"   ç›®æ ‡ä½ç½®: X={moveL_target[0]:.4f}m, Y={moveL_target[1]:.4f}m, Z={moveL_target[2]:.4f}m")
            print(
                f"   ç›®æ ‡å§¿æ€: Roll={math.degrees(moveL_target[3]):.2f}Â°, Pitch={math.degrees(moveL_target[4]):.2f}Â°, Yaw={math.degrees(moveL_target[5]):.2f}Â°")
            print(f"   è¿åŠ¨å‚æ•°: é€Ÿåº¦={self.moveL_speed}m/s, åŠ é€Ÿåº¦={self.moveL_acc}m/sÂ²")
            print("=" * 70)

            # è°ƒç”¨URæœºæ¢°è‡‚moveLæ¥å£ï¼ˆéœ€ç¡®ä¿SDKæ¥å£å‚æ•°åŒ¹é…ï¼‰
            self.robot.moveL(
                target_pose=moveL_target,
                speed=self.moveL_speed,
                acceleration=self.moveL_acc
            )

            print("âœ… moveLè¿åŠ¨å®Œæˆ")
            return True
        except Exception as e:
            print(f"âŒ moveLè¿åŠ¨å¤±è´¥: {str(e)}")
            return False

    """
    11. å›¾åƒä¿¡æ¯ç»˜åˆ¶ï¼ˆä¸å˜ï¼Œå®æ—¶æ˜¾ç¤ºä½å§¿ï¼‰
    """

    def draw_pose_info(self, image, robot_pose, fps, moveL_status=None):
        # 1. æ¨¡å¼æ ‡è¯†
        cv2.putText(image, "Eye-in-Hand (Dynamic Pose)", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 165, 255), 2)

        # 2. æ£€æµ‹çŠ¶æ€
        status_text = "Target Found" if self.found_target else "No Target"
        status_color = (0, 255, 0) if self.found_target else (0, 0, 255)
        cv2.putText(image, status_text, (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, status_color, 2)

        # 3. ä¸­å¿ƒç‚¹åæ ‡
        center_text = f"Center: {self.last_target_center}" if self.last_target_center else "Center: None"
        cv2.putText(image, center_text, (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)

        # 4. ç›®æ ‡æ·±åº¦
        depth_text = f"Depth: {self.last_center_depth:.4f}m" if self.last_center_depth else "Depth: Invalid"
        depth_color = (0, 255, 0) if (self.last_center_depth and self.last_center_depth >= 0.10) else (0, 0, 255)
        cv2.putText(image, depth_text, (10, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, depth_color, 2)

        # 5. å®æ—¶åŸºåº§ä½å§¿ï¼ˆå…³é”®ï¼šæ˜¾ç¤ºåŠ¨æ€å˜åŒ–çš„ä½å§¿ï¼‰
        param_y = 150
        param_spacing = 25
        if robot_pose is not None:
            # ä½ç½®
            cv2.putText(image, f"Base X: {robot_pose['position'][0]:.4f}m", (10, param_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.putText(image, f"Base Y: {robot_pose['position'][1]:.4f}m", (10, param_y + param_spacing),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.putText(image, f"Base Z: {robot_pose['position'][2]:.4f}m", (10, param_y + 2 * param_spacing),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            # å§¿æ€ï¼ˆå¼§åº¦è½¬è§’åº¦ï¼‰
            roll_deg = math.degrees(robot_pose["orientation"][0])
            pitch_deg = math.degrees(robot_pose["orientation"][1])
            yaw_deg = math.degrees(robot_pose["orientation"][2])
            cv2.putText(image, f"Roll: {roll_deg:.2f}Â°", (10, param_y + 3 * param_spacing),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(image, f"Pitch: {pitch_deg:.2f}Â°", (10, param_y + 4 * param_spacing),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            cv2.putText(image, f"Yaw: {yaw_deg:.2f}Â°", (10, param_y + 5 * param_spacing),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        else:
            cv2.putText(image, "Base Pose: No Data", (10, param_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        # 6. è¿åŠ¨çŠ¶æ€
        moveL_text = "moveL: " + (moveL_status if moveL_status else "Ready")
        moveL_color = (0, 0, 255) if moveL_status == "running" else (0, 255, 0)
        cv2.putText(image, moveL_text, (10, param_y + 6 * param_spacing),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, moveL_color, 2)

        # 7. FPSå’Œæ“ä½œæç¤º
        cv2.putText(image, f"FPS: {fps:.1f}", (10, param_y + 7 * param_spacing),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        cv2.putText(image, "Press 'n':Move | 's':Save | 'q':Quit",
                    (10, image.shape[0] - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)

        return image